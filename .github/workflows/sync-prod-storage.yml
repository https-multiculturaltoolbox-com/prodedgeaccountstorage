name: Sync prodedgeaccountstorage to repo (1GB commits, no git in container)

on:
  schedule:
    - cron: "0 2 * * *"   # daily 02:00 UTC
  workflow_dispatch:

permissions:
  contents: write

env:
  COMMIT_BYTES: "1073741824"   # 1 GB

jobs:
  sync:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout (shallow)
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Free up disk space
        run: |
          sudo rm -rf /usr/share/dotnet /opt/ghc "/usr/local/share/boost" "$AGENT_TOOLSDIRECTORY" || true
          df -h

      - name: Download changed blobs (Azure CLI only â€” no git here)
        uses: azure/CLI@v2
        env:
          AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}
          AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}
        with:
          azcliversion: 2.63.0
          inlineScript: |
            set -eu

            ROOT="azure/prodedgeaccountstorage"
            MANIFEST_DIR=".sync-manifest"
            PENDING="$MANIFEST_DIR/_pending.txt"

            mkdir -p "$ROOT" "$MANIFEST_DIR"
            : > "$PENDING"   # clear list of newly-downloaded files

            echo "Listing containers in: $AZURE_STORAGE_ACCOUNT"
            az storage container list \
              --account-name "$AZURE_STORAGE_ACCOUNT" \
              --account-key "$AZURE_STORAGE_KEY" \
              --query "[].name" -o tsv | while IFS= read -r c; do
                [ -z "$c" ] && continue
                echo "::group::Container $c"
                TARGET="$ROOT/$c"
                MANIFEST="$MANIFEST_DIR/$c.tsv"
                mkdir -p "$TARGET"
                [ -f "$MANIFEST" ] || : > "$MANIFEST"

                # Enumerate remote blobs: name, etag, size
                az storage blob list \
                  --account-name "$AZURE_STORAGE_ACCOUNT" \
                  --account-key "$AZURE_STORAGE_KEY" \
                  --container-name "$c" \
                  --query "[].{name:name,etag:properties.etag,size:properties.contentLength}" \
                  -o tsv | while IFS=$'\t' read -r name etag size; do
                      [ -z "$name" ] && continue
                      # Lookup existing etag by blob name in manifest (format: etag<TAB>name)
                      existing_etag="$(awk -F'\t' -v n="$name" '$2==n {print $1; exit}' "$MANIFEST" 2>/dev/null || true)"
                      if [ "$existing_etag" = "$etag" ]; then
                        # Up-to-date; skip
                        continue
                      fi

                      # Ensure local subdir exists
                      dirp="$(dirname "$TARGET/$name")"
                      [ -d "$dirp" ] || mkdir -p "$dirp"

                      # Download single blob
                      az storage blob download \
                        --account-name "$AZURE_STORAGE_ACCOUNT" \
                        --account-key "$AZURE_STORAGE_KEY" \
                        --container-name "$c" \
                        --name "$name" \
                        --file "$TARGET/$name" \
                        --overwrite \
                        --no-progress 1>/dev/null

                      # Update manifest: remove old line for this name, then append new etag+name
                      tmpmf="$MANIFEST.tmp"
                      awk -F'\t' -v n="$name" '!(NF>=2 && $2==n)' "$MANIFEST" > "$tmpmf" 2>/dev/null || true
                      printf "%s\t%s\n" "$etag" "$name" >> "$tmpmf"
                      mv "$tmpmf" "$MANIFEST"

                      # Record downloaded path to be committed later
                      printf "%s\n" "$TARGET/$name" >> "$PENDING"
                  done

                echo "::endgroup::"
              done

            echo "Pending file list written to $PENDING"
            echo "Summary: $(wc -l < "$PENDING" | tr -d ' ') files downloaded."

      - name: Commit & push in ~1GB chunks (host VM)
        if: always()
        run: |
          set -euo pipefail
          ROOT="azure/prodedgeaccountstorage"
          MANIFEST_DIR=".sync-manifest"
          PENDING="$MANIFEST_DIR/_pending.txt"
          THRESH=${COMMIT_BYTES:-1073741824}

          if [ ! -s "$PENDING" ]; then
            echo "No new/changed files to commit."
            exit 0
          fi

          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git config --global --add safe.directory "$GITHUB_WORKSPACE"

          bytes=0
          count=0
          chunk=1

          commit_chunk () {
            local label="$1"
            if [ -n "$(git status --porcelain)" ]; then
              git commit -m "$label ($(date -u +'%Y-%m-%d %H:%M:%S UTC'))"
              git push
            fi
          }

          # Add files one-by-one until we reach ~1GB; then commit and continue.
          while IFS= read -r path; do
            [ -f "$path" ] || continue
            sz=$(stat -c %s "$path")
            git add -- "$path"
            count=$((count+1))
            bytes=$((bytes+sz))
            # Stage manifest only on the first chunk so it lands once
            if [ "$chunk" -eq 1 ]; then
              git add -- "$MANIFEST_DIR"
            fi

            if [ "$bytes" -ge "$THRESH" ]; then
              mb=$((bytes/1024/1024))
              commit_chunk "Sync (chunk $chunk ~${mb} MB)"
              bytes=0
              chunk=$((chunk+1))
            fi
          done < "$PENDING"

          # Final commit for remaining files
          if [ "$bytes" -gt 0 ] || [ "$chunk" -eq 1 ]; then
            mb=$(( (bytes>0?bytes:0)/1024/1024 ))
            commit_chunk "Sync (final chunk ~${mb} MB)"
          fi

          # Clean up the pending list
          : > "$PENDING"

      - name: Final df -h
        run: df -h
